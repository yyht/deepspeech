data_dir=ASR/chinese/oslr_8000_v1/
bert_config_file="./deepspeech/config/deepspeech.json"
vocab_file="./deepspeech/data/chinese_vocab/alphabet4k.txt"
output_dir="ASR/gaode_oslr_8000_sparse_reduced_length_new_latest/"
train_file="ASR/chinese/oslr_8000_v1/chinese_file_list.txt"
init_checkpoint="ASR/gaode_oslr_8000_sparse_reduced_length_new_latest/model.ckpt-30000"
train_batch_size=16
num_gpus=1
num_accumulated_batches=1
learning_rate=1e-3
weight_decay_rate=0.9
warmup_proportion=0.1
lr_decay_power=1.0
distributed_mode="collective_reduce"
layerwise_lr_decay_power=0.0
num_train_epochs=20
train_examples=500000
save_checkpoints_steps=1000
log_step_count_steps=1000
keep_checkpoint_max=10
max_duration=20
samples_per_second=8000
transcript_seq_length=96
do_distributed_training=True
ctc_loss_type=sparse_ctc
audio_featurizer_config_path="ASR/gaode_oslr_8000_sparse_reduced_length_new_latest/audio_featurizer_config.json"
featurizer_aug_config_path="ASR/gaode_oslr_8000_sparse_reduced_length_new_latest/featurizer_aug_config.json"
if_focal_ctc=False
alpha=0.99
gamma=1.0